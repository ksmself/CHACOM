{
  "_from": "hanzi-tokenizer@^1.7.0",
  "_id": "hanzi-tokenizer@1.22.0",
  "_inBundle": false,
  "_integrity": "sha512-Wrp3ihsoXwcMhoWf+gNvPRutIeH7h5E2U53AWpXF1XzZuJ7c8tuAXdllNU5a7MVmS44cjvbiKRLKKft7dImW5w==",
  "_location": "/hanzi-tokenizer",
  "_phantomChildren": {},
  "_requested": {
    "type": "range",
    "registry": true,
    "raw": "hanzi-tokenizer@^1.7.0",
    "name": "hanzi-tokenizer",
    "escapedName": "hanzi-tokenizer",
    "rawSpec": "^1.7.0",
    "saveSpec": null,
    "fetchSpec": "^1.7.0"
  },
  "_requiredBy": [
    "/hanzi-to-pinyin"
  ],
  "_resolved": "https://registry.npmjs.org/hanzi-tokenizer/-/hanzi-tokenizer-1.22.0.tgz",
  "_shasum": "c37e1bf172c75ae3d5cffb1f488eb5b57286902d",
  "_spec": "hanzi-tokenizer@^1.7.0",
  "_where": "C:\\Users\\김승미\\Desktop\\for-portfolio\\2021-April\\prepare\\back\\node_modules\\hanzi-to-pinyin",
  "author": {
    "name": "Pepe Becker",
    "email": "mail@pepebecker.com",
    "url": "http://pepebecker.com"
  },
  "bugs": {
    "url": "https://github.com/pepebecker/hanzi-tokenizer/issues"
  },
  "bundleDependencies": false,
  "dependencies": {
    "mdbg": "^1.31.0"
  },
  "deprecated": false,
  "description": "Convert Chinese text to list of Chinese words",
  "devDependencies": {
    "mocha": "^5.2.0",
    "should": "^13.2.3"
  },
  "files": [],
  "homepage": "https://github.com/pepebecker/hanzi-tokenizer#readme",
  "keywords": [
    "chinese",
    "hanzi",
    "mandarin",
    "pinyin",
    "tokens"
  ],
  "license": "MIT",
  "main": "index.js",
  "name": "hanzi-tokenizer",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/pepebecker/hanzi-tokenizer.git"
  },
  "scripts": {
    "test": "mocha --timeout 20000"
  },
  "version": "1.22.0"
}
